<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Daniel J. Hicks">
<meta name="dcterms.date" content="2023-02-16">

<title>tmfast fits topic models fast</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#mathematical-background" id="toc-mathematical-background" class="nav-link" data-scroll-target="#mathematical-background">Mathematical background</a></li>
  <li><a href="#example-1-a-simulated-corpus" id="toc-example-1-a-simulated-corpus" class="nav-link" data-scroll-target="#example-1-a-simulated-corpus">Example 1: A simulated corpus</a>
  <ul class="collapse">
  <li><a href="#simulation-parameters" id="toc-simulation-parameters" class="nav-link" data-scroll-target="#simulation-parameters">Simulation parameters</a></li>
  <li><a href="#draw-true-topic-distributions" id="toc-draw-true-topic-distributions" class="nav-link" data-scroll-target="#draw-true-topic-distributions">Draw true topic distributions</a></li>
  <li><a href="#draw-true-word-distributions" id="toc-draw-true-word-distributions" class="nav-link" data-scroll-target="#draw-true-word-distributions">Draw true word distributions</a></li>
  <li><a href="#document-lengths" id="toc-document-lengths" class="nav-link" data-scroll-target="#document-lengths">Document lengths</a></li>
  <li><a href="#draw-corpus" id="toc-draw-corpus" class="nav-link" data-scroll-target="#draw-corpus">Draw corpus</a></li>
  <li><a href="#fit-the-topic-model" id="toc-fit-the-topic-model" class="nav-link" data-scroll-target="#fit-the-topic-model">Fit the topic model</a></li>
  <li><a href="#fitting-a-conventional-topic-model-stm" id="toc-fitting-a-conventional-topic-model-stm" class="nav-link" data-scroll-target="#fitting-a-conventional-topic-model-stm">Fitting a conventional topic model (stm)</a></li>
  <li><a href="#assessing-accuracy-word-topic-distributions" id="toc-assessing-accuracy-word-topic-distributions" class="nav-link" data-scroll-target="#assessing-accuracy-word-topic-distributions">Assessing accuracy: Word-topic distributions</a></li>
  <li><a href="#topic-document-distributions" id="toc-topic-document-distributions" class="nav-link" data-scroll-target="#topic-document-distributions">Topic-document distributions</a></li>
  </ul></li>
  <li><a href="#example-2-victorian-fiction" id="toc-example-2-victorian-fiction" class="nav-link" data-scroll-target="#example-2-victorian-fiction">Example 2: Victorian fiction</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><code>tmfast</code> fits topic models fast</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    Daniel J. Hicks <a href="https://orcid.org/0000-0001-7945-4416" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of California, Merced
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 16, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Topic modeling is a natural language processing (NLP) technique popular among digital humanists, computational social scientists, and data scientists working with textual data (eg, product reviews) <strong>[cites]</strong>. Compared to methods such as vector space embeddings or general-use clustering algorithms such as <span class="math inline">\(k\)</span>-means, a key advantage of topic modeling is that it simultaneously clusters both text units (terms or phrases) and documents, enabling analysts to provide human-meaningful, domain-specific labels to the clusters (topics).</p>
<p>However, a key disadvantage of topic modeling is that the models are relatively computationally intensive and slow to fit. This strongly discourages analysts from fitting and comparing multiple models, which is arguably the best way to determine to what extent results are sensitive to researcher degrees of freedom <strong>[Gelman]</strong>. Instead, typically analysts fit a few models to a given corpus and focus interpretation on a single “best” model (which is often chosen by informal assessments of “interpretability” of the fitted topics).</p>
<p>This paper reports <code>tmfast</code>, an R package designed to facilitate a multiple-model approach by using a significantly faster fitting algorithm. After giving a brief mathematical background, I walk through two examples of <code>tmfast</code> in action: generating and fitting models to a simulated text corpus, and then fitting models to a collection of books by different authors retrieved from Project Gutenberg. Note that both of these examples are supervised cases — the true topics are known <em>a priori</em> — and so I can use a method from <strong>[Malaterre and]</strong> to assess the goodness of fit. In addition, I also fit models using the <code>stm</code> package — generally regarded as the state of the art in topic modelling in R — and compare the models fitted by the two packages.</p>
</section>
<section id="mathematical-background" class="level1">
<h1>Mathematical background</h1>
<p>Topic modeling is typically framed using a generative model. A corpus <span class="math inline">\(C\)</span> is defined by a fixed vocabulary or collection of terms <span class="math inline">\(T\)</span>; a collection of <span class="math inline">\(k\)</span> topics <span class="math inline">\(B\)</span>, where each topic <span class="math inline">\(\beta \in B\)</span> is a multinomial distribution over <span class="math inline">\(W\)</span>; and parameters <span class="math inline">\(\lambda &gt; 0\)</span> and <span class="math inline">\(\alpha = (\alpha_1, \ldots, \alpha_k)\)</span> with each <span class="math inline">\(\alpha_i &gt; 0\)</span>. Then a document <span class="math inline">\(d\)</span> is generated as follows:</p>
<ol type="1">
<li>Draw the total length <span class="math inline">\(N_d\)</span> of <span class="math inline">\(d\)</span> from a Poisson distribution, <span class="math inline">\(N_ds \sim \textrm{Poisson}(\lambda)\)</span> (other distributions over the whole numbers might be used here, eg, negative binomial)</li>
<li>Draw a (<span class="math inline">\(k\)</span>-element) topic distribution <span class="math inline">\(\theta_d\)</span> from the Dirichlet distribution defined by <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\theta_d \sim \textrm{Dir}(\alpha)\)</span></li>
<li>For each token <span class="math inline">\(t_i\)</span> (<span class="math inline">\(i = 1, \ldots, N\)</span>),
<ol type="a">
<li>Draw a topic <span class="math inline">\(b_i \sim \textrm{Multinomial}(\theta_d)\)</span></li>
<li>Draw a term from the topic, <span class="math inline">\(t_i \sim b_i\)</span> <span class="citation" data-cites="BleiLatentDirichletAllocation2003">[@BleiLatentDirichletAllocation2003 996]</span>.</li>
</ol></li>
</ol>
<p>This generative model is used to define a joint probability distribution that is then fit to the data (observed document lengths and token counts) using numerical methods such as variational Bayes.</p>
<p><span class="citation" data-cites="RoheVintageFactorAnalysis2020">@RoheVintageFactorAnalysis2020</span> take a different approach to topic modeling, viewing it through the lens of principal component analysis (PCA) and the varimax rotation.</p>
<p>Consider a rectangular dataset <span class="math inline">\(X\)</span> with <span class="math inline">\(n\)</span> observations of <span class="math inline">\(p\)</span> variables (<span class="math inline">\(n \times p\)</span>). In a statistics or data science context, PCA is used for <em>dimension reduction</em>, representing these data with <span class="math inline">\(k &lt; p\)</span> dimensions while preserving as much of the original variance as possible. Contemporary approaches to PCA use the singular value decomposition</p>
<p><span class="math display">\[ X = U \Sigma V^t = U L^t \]</span></p>
<p>where <span class="math inline">\(U\)</span> is a <span class="math inline">\(n \times n\)</span> orthogonal matrix (the column vectors are orthogonal and length 1), <span class="math inline">\(\Sigma\)</span> is a <span class="math inline">\(n \times p\)</span> diagonal matrix (all non-diagonal entries are 0), and <span class="math inline">\(V\)</span> is a <span class="math inline">\(p \times p\)</span> orthogonal matrix. <span class="math inline">\(L = V \Sigma^t\)</span> is a <span class="math inline">\(p \times n\)</span> matrix called the <em>loadings</em>. When <span class="math inline">\(p &lt; n\)</span> (that is, more observations than variables) then columns <span class="math inline">\(p+1, p+2, \ldots, n\)</span> of the loadings will be zero, and columns <span class="math inline">\(1, 2, \ldots, p\)</span> can be interpreted as a new set of <span class="math inline">\(p\)</span> variables constructed from the observed <span class="math inline">\(p\)</span> variables. The rows of <span class="math inline">\(U\)</span> are called the <em>scores</em>; they represent the values of the observations in the new variables.</p>
<p>If <span class="math inline">\(X\)</span> is centered (mean of each column/variable is 0) then the SVD is related to the covariance of the original variables in such a way that the new variables are ordered from greatest to least variance, and the original and new variables have the same total variance. So if we restrict our attention to the first <span class="math inline">\(k\)</span> new variables we will have a smaller representation of the original dataset that captures as much of the original variance as possible. Formally, let <span class="math inline">\(U_k\)</span> be the <span class="math inline">\(n \times k\)</span> matrix with columns <span class="math inline">\(1, \ldots, k\)</span> of <span class="math inline">\(U\)</span> and <span class="math inline">\(L_k = V_k \Sigma_k^t\)</span> the corresponding <span class="math inline">\(p \times k\)</span> partial loadings matrix. Then <span class="math inline">\(X \approx U_k \Sigma_k V_k^t\)</span>.</p>
<p>The loadings matrix is generally not easy to interpret, because the new variables are arbitrary linear combinations of the original variables. Such interpretations are essential in factor analysis, which attempts to identify interpretable latent variables from the data, such as psychological constructs corresponding to (weighted) sets of items in a survey instrument.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Psychometricians proposed to address this problem by finding a <span class="math inline">\(k \times k\)</span> orthogonal<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> matrix <span class="math inline">\(T\)</span></p>
<p><span class="math display">\[ U_k L_k^t = U_k T^t T L_k^t = U_k T^t (L_k T)^t \]</span></p>
<p>that (roughly) makes the “rotated” scores and loadings, <span class="math inline">\(U_k T^t\)</span> and <span class="math inline">\(L_k T\)</span>, as <em>sparse</em> as possible, that is, have as few non-zero entries as possible. This makes the new variables much more interpretable, as generalizations or abstractions of a small collection of observed variables. Because orthogonal matrices generalize rotations and the method for finding this <span class="math inline">\(T\)</span> involves maximizing a total variance, this method is called the <em>varimax rotation</em>.</p>
<p>Finally, to semi-formally motivate a connection between PCA and topic modeling, consider <span class="math inline">\(r_{td}\)</span>, the occurrence rate of term <span class="math inline">\(t\)</span> in document <span class="math inline">\(d\)</span>. This rate estimates the conditional probability of <span class="math inline">\(t\)</span> given <span class="math inline">\(d\)</span>:</p>
<p><span class="math display">\[ r_{td} \approx \Pr(t | d) = \sum_i \Pr(t | b_i) \Pr(b_i | d) = \sum_i b_i \theta_d, \]</span></p>
<p>with a slight abuse of notation. In other words, topic modeling can be seen as factoring the (more-or-less observed) term-document distribution into two sets of latent distributions, term-topic and topic-document, much like PCA factors a data matrix into scores and loadings in latent variables. See <span class="citation" data-cites="RoheVintageFactorAnalysis2020">@RoheVintageFactorAnalysis2020</span> lemma 5.2 for a formal development of this connection.</p>
<p>The upshot is that the latent variables constructed using PCA + varimax can be interpreted as topics. Sparsity means that a given document will have near-zero value for all but a few topics, and a given topic will have near-zero value for all but a few documents.</p>
<p>The most obvious potential advantage of this approach is speed. Text data is typically extremely sparse — documents typically contain only a small fraction of the words in the full vocabulary — and efficient algorithms have been developed for partial SVD of sparse matrices <span class="citation" data-cites="BaglamaAugmentedImplicitlyRestarted2005">[@BaglamaAugmentedImplicitlyRestarted2005]</span>.</p>
<p>The <code>tmfast</code> package implements this PCA + varimax approach to topic modeling in R, with specific support for the tidyverse idiom. The <code>irlba</code> package <strong>[cite]</strong> is used for efficient SVD (by default; users can specify an alternative SVD method if they prefer).</p>
</section>
<section id="example-1-a-simulated-corpus" class="level1">
<h1>Example 1: A simulated corpus</h1>
<p><code>tmfast</code> also includes a collection of functions to generate a simulated corpus according to the standard generative model. In this section, we use these functions to generate a corpus, fit topic models using <code>tmfast</code> and <code>stm</code> <strong>[cite]</strong> — widely used for topic modeling in R — and compare their respective ability to identify the true topics used to generate the corpus.</p>
<p>We first load the <code>tidyverse</code> suite, the <code>lpSolve</code> package to match fitted and true topics, the <code>tictoc</code> package to calculate wall compute times, and <code>tmfast</code> and <code>stm</code>. The <code>tidytext</code> package is also loaded for its <code>stm</code> tidiers (eg, functions to represent a fitted <code>stm</code> model as a dataframe).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lpSolve)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tictoc)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tmfast)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stm)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="simulation-parameters" class="level2">
<h2 class="anchored" data-anchor-id="simulation-parameters">Simulation parameters</h2>
<p>We create simulated text data following the data-generating process assumed by LDA. Specifically, each document will be generated from one of several “journals.” Each journal corresponds to a topic, and vice versa, in that documents from journal <span class="math inline">\(j\)</span> will tend to have a much greater probability for topic <span class="math inline">\(j\)</span> than the other topics.</p>
<p>We first specify the number of topics/journals <code>k</code>, and the number of documents to draw from each journal <code>Mj</code>, for a total of <code>M = Mj * k</code> documents in the corpus. We also specify the length of the vocabulary (total unique words) as a multiple of the total number of documents <code>M</code>. Document lengths are generated using a negative binomial distribution, using the size-mean parameterization. Per <code>?NegBinomial</code>, the standard deviation of document lengths in this parameterization is <span class="math inline">\(\sqrt{\mu + \frac{\mu^2}{\mathrm{size}}}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">=</span> <span class="dv">10</span>                <span class="co"># Num. topics / journals</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>Mj <span class="ot">=</span> <span class="dv">100</span>              <span class="co"># Num. documents per journal</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>M <span class="ot">=</span> Mj<span class="sc">*</span>k              <span class="co"># Total corpus size</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>vocab <span class="ot">=</span> M             <span class="co"># Vocabulary length</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Negative binomial distribution of doc lengths</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>size <span class="ot">=</span> <span class="dv">10</span>             <span class="co"># Size and mean</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">=</span> <span class="dv">300</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(mu <span class="sc">+</span> mu<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>size)  <span class="co"># Resulting SD of document sizes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 96.43651</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Dirichlet distributions for topic-docs and word-topics</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>topic_peak <span class="ot">=</span> .<span class="dv">8</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>topic_scale <span class="ot">=</span> <span class="dv">10</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>word_beta <span class="ot">=</span> <span class="fl">0.1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Because the simulations involve drawing samples using a RNG, we first set a seed.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2022-06-19</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="draw-true-topic-distributions" class="level2">
<h2 class="anchored" data-anchor-id="draw-true-topic-distributions">Draw true topic distributions</h2>
<p>We generate the true topic-document distributions <span class="math inline">\(p(\theta = t | \mathrm{doc}_m)\)</span>, often simply called <span class="math inline">\(\theta\)</span> or <span class="math inline">\(\gamma\)</span>. In this vignette we use <span class="math inline">\(\theta\)</span> for the true distribution and <span class="math inline">\(\gamma\)</span> for the fitted distribution in the topic model. Each document’s <span class="math inline">\(\theta\)</span> is sampled from a Dirichlet distribution (<code>rdirichlet()</code>), with the parameter <span class="math inline">\(\mathbf{\alpha}\)</span> corresponding to the document’s journal <span class="math inline">\(j\)</span>. The variable <code>theta</code> is a <code>M</code> by <code>k</code> matrix; <code>theta_df</code> is a tidy representation with columns <code>doc</code>, <code>topic</code>, and <code>prob</code>. The visualization confirms that documents are generally most strongly associated with the corresponding topics, though with some noise.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Journal-specific alpha, with a peak value (.8 by default) and uniform otherwise</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">=</span> <span class="fu">map</span>(<span class="dv">1</span><span class="sc">:</span>k, </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>            <span class="sc">~</span><span class="fu">rdirichlet</span>(Mj, <span class="fu">peak_alpha</span>(k, .x, </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>                                       <span class="at">peak =</span> topic_peak, </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>                                       <span class="at">scale =</span> topic_scale))) <span class="sc">|&gt;</span> </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">reduce</span>(rbind)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>theta_df <span class="ot">=</span> theta <span class="sc">|&gt;</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">'doc'</span>, </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">.name_repair =</span> tmfast<span class="sc">:::</span>make_colnames) <span class="sc">|&gt;</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">doc =</span> <span class="fu">as.integer</span>(doc)) <span class="sc">|&gt;</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="fu">starts_with</span>(<span class="st">'V'</span>),</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>                 <span class="at">names_to =</span> <span class="st">'topic'</span>,</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                 <span class="at">values_to =</span> <span class="st">'prob'</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(theta_df, <span class="fu">aes</span>(doc, topic, <span class="at">fill =</span> prob)) <span class="sc">+</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_tile</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="draw-true-word-distributions" class="level2">
<h2 class="anchored" data-anchor-id="draw-true-word-distributions">Draw true word distributions</h2>
<p>Next we generate the true word-topic distributions <span class="math inline">\(p(\phi = w | \theta = t)\)</span>, often designed as either <span class="math inline">\(\phi\)</span> or <span class="math inline">\(\beta\)</span>. We use <span class="math inline">\(\phi\)</span> for the true distribution and <span class="math inline">\(\beta\)</span> for the fitted distribution. We sample these distributions from a symmetric Dirichlet distribution over the length of the vocabulary with <span class="math inline">\(\alpha = .01\)</span>. Tile and Zipfian (probability vs.&nbsp;rank on a log-log scale) plots confirm these distributions are working correctly.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="do">## phi_j:  Word distribution for topic j</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>phi <span class="ot">=</span> <span class="fu">rdirichlet</span>(k, word_beta, <span class="at">k =</span> vocab)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Word distributions</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>phi <span class="sc">|&gt;</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">'topic'</span>, </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">.name_repair =</span> tmfast<span class="sc">:::</span>make_colnames) <span class="sc">|&gt;</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="fu">starts_with</span>(<span class="st">'V'</span>),</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>                 <span class="at">names_to =</span> <span class="st">'word'</span>,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>                 <span class="at">values_to =</span> <span class="st">'prob'</span>) <span class="sc">|&gt;</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(topic, word, <span class="at">fill =</span> (prob))) <span class="sc">+</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_tile</span>() <span class="sc">+</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_discrete</span>(<span class="at">breaks =</span> <span class="cn">NULL</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Zipf's law</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>phi <span class="sc">|&gt;</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">'topic'</span>, </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">.name_repair =</span> \(x)(<span class="fu">str_c</span>(<span class="st">'word'</span>, <span class="dv">1</span><span class="sc">:</span>vocab))) <span class="sc">|&gt;</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="fu">starts_with</span>(<span class="st">'word'</span>),</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">names_to =</span> <span class="st">'word'</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">values_to =</span> <span class="st">'prob'</span>) <span class="sc">|&gt;</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(topic) <span class="sc">|&gt;</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">rank =</span> <span class="fu">rank</span>(<span class="fu">desc</span>(prob))) <span class="sc">|&gt;</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(topic, rank) <span class="sc">|&gt;</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(rank <span class="sc">&lt;</span> vocab<span class="sc">/</span><span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(rank, prob, <span class="at">color =</span> topic)) <span class="sc">+</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_log10</span>() <span class="sc">+</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_log10</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-5-2.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="document-lengths" class="level2">
<h2 class="anchored" data-anchor-id="document-lengths">Document lengths</h2>
<p>Again, document lengths are drawn from a negative binomial distribution.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="do">## N_i:  Length of document i</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">=</span> <span class="fu">rnbinom</span>(M, <span class="at">size =</span> size, <span class="at">mu =</span> mu)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   93.0   240.8   300.5   308.6   364.5   774.0 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 95.1555</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="draw-corpus" class="level2">
<h2 class="anchored" data-anchor-id="draw-corpus">Draw corpus</h2>
<p>Finally we draw the corpus, the observed word counts for each document. This is the most time-consuming step in this script, much slower than actually fitting the topic model. Experimenting with this simulation, we found that <code>log1p()</code> scaling of the word counts produced better results than other scaling techniques (eg, dividing by the total length of each document, scaling words by their standard deviation) for accounting for radical differences in document length.</p>
<div class="cell" data-hash="paper_cache/html/unnamed-chunk-7_41cbab7a7888883f7f78577da93fcb4e">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>corpus <span class="ot">=</span> <span class="fu">draw_corpus</span>(N, theta, phi)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>24.938 sec elapsed</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>dtm <span class="ot">=</span> <span class="fu">mutate</span>(corpus, <span class="at">n =</span> <span class="fu">log1p</span>(n))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="fit-the-topic-model" class="level2">
<h2 class="anchored" data-anchor-id="fit-the-topic-model">Fit the topic model</h2>
<p>Fitting the topic model is extremely fast. Note that we can request multiple values of <span class="math inline">\(k\)</span> (numbers of topics) in a single call. Other topic modelling packages typically fit only a single value of <span class="math inline">\(k\)</span> at a time.</p>
<p>Under the hood, we cast the document-term matrix to a sparse matrix class if necessary. Then we extract the maximum number of desired principal components using <code>irlba::prcomp_irlba()</code>, centering but not scaling the logged word counts. (Experiments with this simulation indicated that scaling makes it more difficult to construct probability distributions later.) Next we use the base R function <code>stats:varimax()</code> to construct a preliminary varimax rotation of the principal components. Because the direction of factors is arbitrary as far as varimax is concerned, but meaningful when we convert things to probability distributions, we check the skew of each factor’s loadings in the preliminary fit, and reverse the factors with negative skew (long left tails with relatively large negative values).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>fitted <span class="ot">=</span> <span class="fu">tmfast</span>(dtm, <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, k, <span class="dv">2</span><span class="sc">*</span>k))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.564 sec elapsed</code></pre>
</div>
</div>
<p>The object returned by <code>tmfast()</code> has a simple structure. <code>totalvar</code> and <code>sdev</code> come from the PCA step, giving the total variance across all feature variables and the standard deviation of each extracted principal component. (Note that these PCs do not generally correspond to the varimax-rotated factors/topics.) <code>n</code> contains the sizes (number of factors/topics) fitted for the models, and <code>varimaxes</code> contains the varimax fit for each value of <code>n</code>. The varimax objects each contain three matrices, the rotated <code>loadings</code> (word-topics), the rotation matrix <code>rotmat</code>, and the rotated <code>scores</code> (document-topics). Note that these are not stored as probability distributions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(fitted, <span class="at">max.level =</span> 2L)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>List of 9
 $ totalvar: num 138
 $ sdev    : num [1:20] 3.26 3.06 3.01 2.97 2.93 ...
 $ rows    : chr [1:1000] "1" "2" "3" "4" ...
 $ cols    : chr [1:999] "5" "7" "8" "11" ...
 $ center  : Named num [1:999] 0.4016 0.0943 0.4254 0.2396 0.4093 ...
  ..- attr(*, "names")= chr [1:999] "5" "7" "8" "11" ...
 $ scale   : logi FALSE
 $ rotation: num [1:999, 1:20] -0.00112 0.02725 0.01223 0.00457 -0.00883 ...
  ..- attr(*, "dimnames")=List of 2
 $ n       : num [1:4] 2 3 10 20
 $ varimax :List of 4
  ..$ 2 :List of 3
  ..$ 3 :List of 3
  ..$ 10:List of 3
  ..$ 20:List of 3
 - attr(*, "class")= chr [1:3] "tmfast" "varimaxes" "list"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(fitted<span class="sc">$</span>varimax<span class="sc">$</span><span class="st">`</span><span class="at">5</span><span class="st">`</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> NULL</code></pre>
</div>
</div>
<p>Because the model contains a <code>sdev</code> component, <code>screeplot()</code> works out of the box. Note that the first <span class="math inline">\(k\)</span> PCs have much higher variance than the others, and often the <span class="math inline">\(k\)</span>th PC is somewhat lower than the first <span class="math inline">\(k-1\)</span>. This reflects the highly simplified structure of the simulated data. Real datasets often have a much more gradual decline in the screeplot, likely reflecting the complex hierarchy of topics in actual documents.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">screeplot</span>(fitted)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>It’s also straightforward to calculate the share of total variance covered by successive principal components. Experimenting with this simulation, when some documents are much larger than others, <span class="math inline">\(k\)</span> principal components might cover less than half of the total variance. In this case it covers about 65%. Again, note that the rotated varimax factors don’t correspond to the principal components, but the total covered variance remains the same.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Variance coverage?</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cumsum</span>(fitted<span class="sc">$</span>sdev<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> fitted<span class="sc">$</span>totalvar</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0.07689789 0.14466433 0.21018176 0.27420309 0.33636478 0.39492291
 [7] 0.45196354 0.50563725 0.55705654 0.57380104 0.57606900 0.57828256
[13] 0.58048004 0.58264465 0.58479395 0.58691426 0.58902127 0.59107016
[19] 0.59311409 0.59514063</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">PC =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(fitted<span class="sc">$</span>sdev),</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">cum_var =</span> <span class="fu">cumsum</span>(fitted<span class="sc">$</span>sdev<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> fitted<span class="sc">$</span>totalvar) <span class="sc">|&gt;</span> </span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(PC, cum_var)) <span class="sc">+</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="fitting-a-conventional-topic-model-stm" class="level2">
<h2 class="anchored" data-anchor-id="fitting-a-conventional-topic-model-stm">Fitting a conventional topic model (stm)</h2>
<p>For comparison, we’ll also fit a conventional topic model using the <code>stm</code> package. To address the challenge of picking a number of topics, <code>stm::stm()</code> conducts a topic estimation process when passed <code>K = 0</code>. With the simulation parameters and the random seed used here, this process takes almost 12 seconds and produces a model with 33 topics. We therefore do not run the code below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>corpus <span class="sc">|&gt;</span> </span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cast_sparse</span>(doc, word, n) <span class="sc">|&gt;</span> </span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stm</span>(<span class="at">K =</span> <span class="dv">0</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Setting <code>K = k</code> gives us a fitted topic model in a few seconds, about an order of magnitude slower than <code>tmfast()</code>.</p>
<div class="cell" data-hash="paper_cache/html/unnamed-chunk-13_f110decc355ed5be95f5ff822dd865ce">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>fitted_stm <span class="ot">=</span> corpus <span class="sc">|&gt;</span> </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cast_sparse</span>(doc, word, n) <span class="sc">|&gt;</span> </span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stm</span>(<span class="at">K =</span> k, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4.71 sec elapsed</code></pre>
</div>
</div>
</section>
<section id="assessing-accuracy-word-topic-distributions" class="level2">
<h2 class="anchored" data-anchor-id="assessing-accuracy-word-topic-distributions">Assessing accuracy: Word-topic distributions</h2>
<p>Using simulated data with true word-topic and topic-document distributions lets us check the accuracy of both <code>tmfast</code> and <code>stm</code> models. Here we’ll develop a method proposed by <span class="citation" data-cites="MalaterreEarlyDaysContemporary2022">@MalaterreEarlyDaysContemporary2022</span>, comparing distributions using Hellinger distance. For discrete probability distributions <span class="math inline">\(p, q\)</span> over the same space <span class="math inline">\(X\)</span>, the Hellinger distance is given by</p>
<p><span class="math display">\[ d(p,q) = \frac{1}{\sqrt{2}} \sqrt{\sum_{x \in X} (\sqrt{p(x)} - \sqrt{q(x)})^2} = \frac{1}{\sqrt{2}} \lVert \sqrt p - \sqrt q \rVert_2. \]</span></p>
<p>The last equation means that the Hellinger distance is the Euclidean (<span class="math inline">\(L^2\)</span>-norm) distance between the <em>square roots</em> of the distributions. Some authors working with topic models sometimes compare distributions using the <span class="math inline">\(L^2\)</span>-norm of the distributions themselves, without the square root. But this approach is flawed, since probability distributions can have different lengths in the <span class="math inline">\(L^2\)</span> norm. (For example, the distribution <span class="math inline">\(\left&lt; 1, 0\right&gt;\)</span> has <span class="math inline">\(L^2\)</span> length 1, while <span class="math inline">\(\left&lt; \frac{1}{2}, \frac{1}{2} \right&gt;\)</span> has <span class="math inline">\(L^2\)</span> length approximately 1.19.) Cosine similarity, which is also widely used by text analysts, is directly related to the <span class="math inline">\(L^2\)</span>-norm and has the same problem.</p>
<p>Hellinger distance satisfies the equation <span class="math display">\[ 1 - d^2(p, q) = \sum_{x \in X} \sqrt{p(x)q(x)}. \]</span> When working with topic models, we’re interested in pairwise sets of Hellinger distances, either between all pairs of distributions from a single set (for example, the topic distributions for each document, as used in “discursive space” analysis <em>[cite and xref]</em>) or two sets (for example, comparing fitted vs.&nbsp;true word-topic distributions, as in this section). Working with two sets of distributions <span class="math inline">\(P = \{p_i | i \in I\}\)</span> and <span class="math inline">\(Q = \{q_j | j \in J\}\)</span>, the right-hand side of the last equation is equivalent to a matrix multiplication.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> The <code>tmfast::hellinger()</code> function provides S3 methods for calculating Hellinger pairwise distances given a single dataframe, single matrix, or two dataframes or matrices.</p>
<p>First, however, we need to extract the word-topic distributions. <code>tmfast</code> provides a <code>tidy()</code> method, following the pattern of the topic model tidiers in the <code>tidytext</code> package. Unlike other topic models, <code>tmfast</code> objects can contain multiple models for different values of <span class="math inline">\(k\)</span>. So, in the second argument to <code>tidy()</code>, we need to specify which number of topics we want. The third argument specifies the desired set of distributions, either word-topics (<code>'beta'</code>) or topic-documents (<code>'gamma'</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="do">## beta: fitted varimax loadings, transformed to probability distributions</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">=</span> <span class="fu">tidy</span>(fitted, k, <span class="st">'beta'</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,734 × 3
   token topic     beta
   &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;
 1 5     V02   0.0198  
 2 5     V08   0.00454 
 3 7     V01   0.00344 
 4 7     V02   0.00276 
 5 7     V06   0.000318
 6 8     V01   0.00146 
 7 8     V02   0.00522 
 8 8     V09   0.0195  
 9 11    V02   0.0114  
10 11    V04   0.00610 
# … with 2,724 more rows</code></pre>
</div>
</div>
<p>Word-topic distributions correspond to the varimax factor loadings. These loadings can take any real value. To convert them to probability distributions, within each factor (topic), we trim negative values to 0 and divide each loading by the sum of all loadings. The Zipfian plot below compares the fitted and true word-topic distributions. Consistently across experiments with this simulation, fitted distributions started off a little flatter, then dropped sharply after about 100 words. In other words, the varimax topic model highlights a relatively long list of characteristic words for each topic — the actual distributions have fewer characteristic words — and then ignores the other words.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Compare Zipfian distributions</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_rows</span>({beta <span class="sc">|&gt;</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">type =</span> <span class="st">'fitted'</span>)},</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>        {phi <span class="sc">|&gt;</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>                <span class="fu">t</span>() <span class="sc">|&gt;</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>                <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">'token'</span>, </span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.name_repair =</span> tmfast<span class="sc">:::</span>make_colnames) <span class="sc">|&gt;</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>                <span class="fu">pivot_longer</span>(<span class="fu">starts_with</span>(<span class="st">'V'</span>),</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>                             <span class="at">names_to =</span> <span class="st">'topic'</span>,</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>                             <span class="at">values_to =</span> <span class="st">'beta'</span>) <span class="sc">|&gt;</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>                <span class="fu">mutate</span>(<span class="at">type =</span> <span class="st">'true'</span>)}</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(type, topic) <span class="sc">|&gt;</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">rank =</span> <span class="fu">rank</span>(<span class="fu">desc</span>(beta))) <span class="sc">|&gt;</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(type, topic, rank) <span class="sc">|&gt;</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(rank <span class="sc">&lt;</span> vocab<span class="sc">/</span><span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(rank, beta, <span class="at">color =</span> type, <span class="at">group =</span> <span class="fu">interaction</span>(topic, type))) <span class="sc">+</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_log10</span>() <span class="sc">+</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_log10</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The Zipfian distribution doesn’t tell us which fitted topics might correspond to which true topics. For that, following <span class="citation" data-cites="MalaterreEarlyDaysContemporary2022">@MalaterreEarlyDaysContemporary2022</span>, we’ll use pairwise Hellinger distances. There’s one complication, however. The parameters chosen for this simulation typically end up not drawing some of the words from the vocabulary, and they don’t end up in the same order as the true word-topic matrix <code>phi</code>. Fortunately words are represented as the integers <code>1:vocab</code>, so it’s relatively painless to put them back in order and fill in the gaps (setting the probability for the missing words to be 0 across all topics). In the code block below, we first fix these issues with the words, widen the long dataframe, convert it to a matrix, and then calculate pairwise Hellinger distances with the true word-topic matrix <code>phi</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Hellinger distance of word-topic distributions</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>beta_mx <span class="ot">=</span> beta <span class="sc">|&gt;</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Fix order of words</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">token =</span> <span class="fu">as.integer</span>(token)) <span class="sc">|&gt;</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(token) <span class="sc">|&gt;</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="do">## And dropped words</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">complete</span>(<span class="at">token =</span> <span class="dv">1</span><span class="sc">:</span>vocab, topic, <span class="at">fill =</span> <span class="fu">list</span>(<span class="at">beta =</span> <span class="dv">0</span>)) <span class="sc">|&gt;</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> <span class="st">'topic'</span>,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">values_from =</span> <span class="st">'beta'</span>, <span class="at">values_fill =</span> <span class="dv">0</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>                <span class="at">names_sort =</span> <span class="cn">TRUE</span>) <span class="sc">|&gt;</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Coerce to matrix</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">column_to_rownames</span>(<span class="st">'token'</span>) <span class="sc">|&gt;</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>()</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="fu">hellinger</span>(phi, <span class="fu">t</span>(beta_mx))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            V01       V02       V03       V04       V05       V06       V07
 [1,] 0.9031738 0.1637336 0.9165058 0.9123347 0.8751537 0.8995845 0.9036184
 [2,] 0.9059649 0.8784121 0.9101200 0.8988053 0.1568935 0.9154690 0.8912032
 [3,] 0.9109254 0.8784830 0.9078316 0.8766395 0.8950844 0.8955629 0.8863298
 [4,] 0.9364565 0.9175881 0.1665250 0.9072348 0.9071975 0.8779525 0.9121768
 [5,] 0.8953244 0.9050252 0.9027020 0.8977285 0.8866189 0.9016970 0.1828639
 [6,] 0.9229747 0.9117772 0.8779031 0.8931918 0.9100060 0.1807501 0.9014234
 [7,] 0.1642187 0.9068759 0.9378145 0.8921973 0.9020294 0.9310713 0.8995111
 [8,] 0.9146167 0.8876726 0.9160216 0.8977089 0.9003917 0.9068250 0.8869320
 [9,] 0.8956926 0.9145803 0.9014559 0.1682888 0.8991201 0.9032983 0.8980827
[10,] 0.9112636 0.9152296 0.9052323 0.8935218 0.9000401 0.8869707 0.8837047
            V08       V09       V10
 [1,] 0.9223213 0.8852931 0.8929746
 [2,] 0.9044976 0.8865806 0.9026687
 [3,] 0.9139487 0.1770633 0.9222647
 [4,] 0.9077645 0.9109467 0.9142646
 [5,] 0.8797781 0.8815338 0.8907767
 [6,] 0.8961334 0.8931672 0.9064453
 [7,] 0.9032734 0.9106445 0.9160885
 [8,] 0.8796820 0.9247945 0.1708753
 [9,] 0.8968698 0.8872700 0.9004598
[10,] 0.1616073 0.9255980 0.8824513</code></pre>
</div>
</div>
<p>In this distance matrix, the rows are the true topics and the columns are the fitted topics. Low values correspond to greater similarity. It’s clear that the topics don’t match up perfectly — the minimum in each row is about 0.17 — but there is a clear minimum. We treat this as a linear assignment problem, which is solved rapidly using the <code>lpSolve</code> package. The solution — which matches true to fitted topics — can then be used as a rotation with both the loadings and scores (topic-document distributions). After rotating, the true-fitted pairs are on the diagonal of the Hellinger distance matrix, making it easy to extract and summarize the quality of the fit.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Use lpSolve to match fitted topics to true topics</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>dist <span class="ot">=</span> <span class="fu">hellinger</span>(phi, <span class="fu">t</span>(beta_mx))</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>soln <span class="ot">=</span> <span class="fu">lp.assign</span>(dist)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>soln<span class="sc">$</span>solution</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0    1    0    0    0    0    0    0    0     0
 [2,]    0    0    0    0    1    0    0    0    0     0
 [3,]    0    0    0    0    0    0    0    0    1     0
 [4,]    0    0    1    0    0    0    0    0    0     0
 [5,]    0    0    0    0    0    0    1    0    0     0
 [6,]    0    0    0    0    0    1    0    0    0     0
 [7,]    1    0    0    0    0    0    0    0    0     0
 [8,]    0    0    0    0    0    0    0    0    0     1
 [9,]    0    0    0    1    0    0    0    0    0     0
[10,]    0    0    0    0    0    0    0    1    0     0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Hellinger distance comparison using the lpSolve matching</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hellinger</span>(phi, soln<span class="sc">$</span>solution <span class="sc">%*%</span> <span class="fu">t</span>(beta_mx))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.1637336 0.8751537 0.8852931 0.9165058 0.9036184 0.8995845 0.9031738
 [2,] 0.8784121 0.1568935 0.8865806 0.9101200 0.8912032 0.9154690 0.9059649
 [3,] 0.8784830 0.8950844 0.1770633 0.9078316 0.8863298 0.8955629 0.9109254
 [4,] 0.9175881 0.9071975 0.9109467 0.1665250 0.9121768 0.8779525 0.9364565
 [5,] 0.9050252 0.8866189 0.8815338 0.9027020 0.1828639 0.9016970 0.8953244
 [6,] 0.9117772 0.9100060 0.8931672 0.8779031 0.9014234 0.1807501 0.9229747
 [7,] 0.9068759 0.9020294 0.9106445 0.9378145 0.8995111 0.9310713 0.1642187
 [8,] 0.8876726 0.9003917 0.9247945 0.9160216 0.8869320 0.9068250 0.9146167
 [9,] 0.9145803 0.8991201 0.8872700 0.9014559 0.8980827 0.9032983 0.8956926
[10,] 0.9152296 0.9000401 0.9255980 0.9052323 0.8837047 0.8869707 0.9112636
           [,8]      [,9]     [,10]
 [1,] 0.8929746 0.9123347 0.9223213
 [2,] 0.9026687 0.8988053 0.9044976
 [3,] 0.9222647 0.8766395 0.9139487
 [4,] 0.9142646 0.9072348 0.9077645
 [5,] 0.8907767 0.8977285 0.8797781
 [6,] 0.9064453 0.8931918 0.8961334
 [7,] 0.9160885 0.8921973 0.9032734
 [8,] 0.1708753 0.8977089 0.8796820
 [9,] 0.9004598 0.1682888 0.8968698
[10,] 0.8824513 0.8935218 0.1616073</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hellinger</span>(phi, soln<span class="sc">$</span>solution <span class="sc">%*%</span> <span class="fu">t</span>(beta_mx)) <span class="sc">|&gt;</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">diag</span>() <span class="sc">|&gt;</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.1569  0.1639  0.1674  0.1693  0.1755  0.1829 </code></pre>
</div>
</div>
<p>And we do the same thing with the <code>stm</code> topic model. <strong><code>stm</code> is somewhat more accurate than <code>tmfast</code>, with a median Hellinger distance of about 0.07 compared to 0.18. But <code>stm</code> is significantly slower.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>beta_stm_mx <span class="ot">=</span> <span class="fu">tidy</span>(fitted_stm, <span class="at">matrix =</span> <span class="st">'beta'</span>) <span class="sc">|&gt;</span> </span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Fix order of words</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">term =</span> <span class="fu">as.integer</span>(term)) <span class="sc">|&gt;</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(term) <span class="sc">|&gt;</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    <span class="do">## And dropped words</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">complete</span>(<span class="at">term =</span> <span class="dv">1</span><span class="sc">:</span>vocab, topic, <span class="at">fill =</span> <span class="fu">list</span>(<span class="at">beta =</span> <span class="dv">0</span>)) <span class="sc">|&gt;</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> <span class="st">'topic'</span>,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">values_from =</span> <span class="st">'beta'</span>, <span class="at">values_fill =</span> <span class="dv">0</span>,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">names_sort =</span> <span class="cn">TRUE</span>) <span class="sc">|&gt;</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Coerce to matrix</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">column_to_rownames</span>(<span class="st">'term'</span>) <span class="sc">|&gt;</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>()</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="fu">hellinger</span>(phi, <span class="fu">t</span>(beta_stm_mx))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               1          2          3          4          5          6
 [1,] 0.08551476 0.84250732 0.84248134 0.88213508 0.87444870 0.87157834
 [2,] 0.84329922 0.85367721 0.08226114 0.87003933 0.85853111 0.86964720
 [3,] 0.84814338 0.08498287 0.84966302 0.85873155 0.83485457 0.87730942
 [4,] 0.88728074 0.86458774 0.87596766 0.08716275 0.86137846 0.90341396
 [5,] 0.86509433 0.84154766 0.84198078 0.86693020 0.85183981 0.85492194
 [6,] 0.89275208 0.85457918 0.87148785 0.83690625 0.84770470 0.89097927
 [7,] 0.87604529 0.87475670 0.86935797 0.89497509 0.86136575 0.08427024
 [8,] 0.86179446 0.88513627 0.87104990 0.87765133 0.85763362 0.88206046
 [9,] 0.88272319 0.84014092 0.86831204 0.85799803 0.09038475 0.86010142
[10,] 0.88217135 0.87848592 0.86296463 0.86880249 0.85155013 0.87344130
               7          8          9         10
 [1,] 0.85051526 0.86539658 0.87856817 0.86805865
 [2,] 0.86158904 0.87025988 0.85982995 0.85353582
 [3,] 0.88224633 0.85827133 0.87289308 0.84502101
 [4,] 0.87295764 0.83661054 0.86684110 0.87271693
 [5,] 0.84603547 0.86047913 0.83835750 0.07902295
 [6,] 0.86282228 0.08880347 0.85411829 0.86252234
 [7,] 0.87474253 0.89536072 0.86677860 0.85727623
 [8,] 0.09267689 0.87054310 0.84452997 0.85300612
 [9,] 0.85178500 0.85313348 0.85250779 0.85785724
[10,] 0.84600884 0.85587004 0.09097089 0.84596278</code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>rotation_stm <span class="ot">=</span> <span class="fu">hellinger</span>(phi, <span class="fu">t</span>(beta_stm_mx)) <span class="sc">|&gt;</span> </span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lp.assign</span>() <span class="sc">|&gt;</span> </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    magrittr<span class="sc">::</span><span class="fu">extract2</span>(<span class="st">'solution'</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hellinger</span>(phi, rotation_stm <span class="sc">%*%</span> <span class="fu">t</span>(beta_stm_mx)) <span class="sc">|&gt;</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">diag</span>() <span class="sc">|&gt;</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.07902 0.08445 0.08634 0.08661 0.08999 0.09268 </code></pre>
</div>
</div>
<p>The tidied word-topic distributions can be used in standard ways for further analysis, such as a <a href="https://juliasilge.com/blog/2018/2018-01-25-sherlock-holmes-stm_files/figure-html/unnamed-chunk-6-1.png">Silge plot</a> of the highest probability words for each topic. But because the “words” in this simulation are just integers, and not semantically meaningful, we don’t construct such a plot here.</p>
</section>
<section id="topic-document-distributions" class="level2">
<h2 class="anchored" data-anchor-id="topic-document-distributions">Topic-document distributions</h2>
<p>Finally, we compare fitted and true topic-document distributions. We extract topic-document distributions using the same <code>tidy()</code> function, specifying the matrix <code>gamma</code> and including the rotation above to align the fitted and true topics. Tile and parallel coordinates plots can be used to visualize all of the topic-document distributions. These show that the <code>tmfast</code> models successfully recover the overall association of each document’s journal with a distinctive topic.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>gamma_df <span class="ot">=</span> <span class="fu">tidy</span>(fitted, k, <span class="st">'gamma'</span>, </span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">rotation =</span> soln<span class="sc">$</span>solution)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in tidy.tmfast(fitted, k, "gamma", rotation = soln$solution): Rotating
scores</code></pre>
</div>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>gamma_df <span class="sc">|&gt;</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">document =</span> <span class="fu">as.integer</span>(document)) <span class="sc">|&gt;</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(document, topic, <span class="at">fill =</span> gamma)) <span class="sc">+</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_raster</span>() <span class="sc">+</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="cn">NULL</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>gamma_df <span class="sc">|&gt;</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">document =</span> <span class="fu">as.integer</span>(document),</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">journal =</span> (document <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">%/%</span> Mj <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">|&gt;</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(topic, gamma, </span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">group =</span> document, <span class="at">color =</span> <span class="fu">as.factor</span>(journal))) <span class="sc">+</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">alpha =</span> .<span class="dv">25</span>) <span class="sc">+</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="fu">vars</span>(journal), <span class="at">scales =</span> <span class="st">'free_x'</span>) <span class="sc">+</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_color_discrete</span>(<span class="at">guide =</span> <span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-19-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>However, the fitted topic-document distributions are flatter than the true ones. Consider the true and fitted distributions for document 1. Compared to the true distribution, the fitted distribution has a somewhat lower probability for topic <code>V01</code> and a somewhat higher probability for the other topics.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(topic, <span class="at">group =</span> 1L)) <span class="sc">+</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">y =</span> theta, <span class="at">color =</span> <span class="st">'true'</span>), </span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">theta =</span> theta[<span class="dv">1</span>,], </span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>                            <span class="at">topic =</span> tmfast<span class="sc">:::</span><span class="fu">make_colnames</span>(<span class="dv">1</span><span class="sc">:</span>k))) <span class="sc">+</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">y =</span> gamma, <span class="at">color =</span> <span class="st">'fitted'</span>), </span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> <span class="fu">filter</span>(gamma_df, document <span class="sc">==</span> <span class="st">'1'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This flatter distribution corresponds to greater entropy. In this simulation, the entropy of the fitted distributions are about 1 bit greater than those of the true distributions. This discrepancy tends to become worse with greater values of <span class="math inline">\(k\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>theta <span class="sc">|&gt;</span> </span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">apply</span>(<span class="dv">1</span>, entropy) <span class="sc">|&gt;</span> </span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.1006  0.6614  0.9715  1.0100  1.3311  2.5821 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(fitted, k, <span class="st">'gamma'</span>) <span class="sc">|&gt;</span> </span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(document) <span class="sc">|&gt;</span> </span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">H =</span> <span class="fu">entropy</span>(gamma)) <span class="sc">|&gt;</span> </span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pull</span>(H) <span class="sc">|&gt;</span> </span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8486  1.7040  1.9319  1.9129  2.1592  2.7673 </code></pre>
</div>
</div>
<p>To mitigate this problem, we add an optional renormalization step when converting document scores to topic-document distributions. Given a discrete probability distribution <span class="math inline">\(P\)</span> with components <span class="math inline">\(p_i\)</span> and entropy <span class="math inline">\(H\)</span>, and a parameter <span class="math inline">\(\beta\)</span>, we can define a new distribution <span class="math inline">\(P'\)</span> with components</p>
<p><span class="math display">\[ p'_i = \frac{p_i^\beta}{\sum_i p_i^\beta} = \frac{p_i^\beta}{Z}\]</span></p>
<p>which has entropy</p>
<p><span class="math display">\[ H' = \frac{1}{Z} \sum_i [p_i^\beta \beta \log p_i] - \log Z.\]</span></p>
<p>That is, we can choose a parameter <span class="math inline">\(\beta\)</span> that renormalizes <span class="math inline">\(P\)</span> to achieve a target entropy <span class="math inline">\(H'\)</span>. In LDA, the target entropy is the expected entropy for topic-document distributions drawn from the Dirichlet prior. <code>tmfast</code> provides convenience functions for calculating this expected entropy; compare this to the mean entropy of the distributions in <code>theta</code> above. <strong>In actual applications, where the Dirichlet prior is an idealization, choosing <span class="math inline">\(\alpha\)</span> to set the target entropy is an important researcher degree of freedom.</strong> It is equivalent to choosing prior parameters in other topic modeling packages.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">peak_alpha</span>(k, <span class="dv">1</span>, topic_peak, topic_scale)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 8.0000000 0.2222222 0.2222222 0.2222222 0.2222222 0.2222222 0.2222222
 [8] 0.2222222 0.2222222 0.2222222</code></pre>
</div>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">expected_entropy</span>(<span class="fu">peak_alpha</span>(k, <span class="dv">1</span>, topic_peak, topic_scale))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.997604</code></pre>
</div>
</div>
<p>Since solving the equation for <span class="math inline">\(H'\)</span> for <span class="math inline">\(\beta\)</span> requires numerical optimization, it’s inefficient to do this every time we call <code>tidy()</code>, especially with large corpora. Instead, <code>tmfast::target_power()</code> is used to run this optimization once, and then return the mean value across all documents. We then use this single value of <span class="math inline">\(\beta\)</span> in all future calls to <code>tidy()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>gamma_power <span class="ot">=</span> <span class="fu">tidy</span>(fitted, k, <span class="st">'gamma'</span>) <span class="sc">|&gt;</span> </span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">target_power</span>(document, gamma, </span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">expected_entropy</span>(<span class="fu">peak_alpha</span>(k, </span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>                                             <span class="dv">1</span>, </span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>                                             topic_peak, </span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>                                             topic_scale)))</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>gamma_power</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.772724</code></pre>
</div>
</div>
<p>The renormalized topic-document distributions have closer entropy to theta. The <code>keep_original</code> argument lets us compare the original and renormalized distributions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>gamma_df <span class="ot">=</span> <span class="fu">tidy</span>(fitted, k, <span class="st">'gamma'</span>, </span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">rotation =</span> soln<span class="sc">$</span>solution, </span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">exponent =</span> gamma_power, </span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">keep_original =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in tidy.tmfast(fitted, k, "gamma", rotation = soln$solution, exponent =
gamma_power, : Rotating scores</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>gamma_df <span class="sc">|&gt;</span> </span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(document) <span class="sc">|&gt;</span> </span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="fu">across</span>(<span class="fu">c</span>(gamma, gamma_rn), entropy)) <span class="sc">|&gt;</span> </span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="fu">across</span>(<span class="fu">c</span>(gamma, gamma_rn), mean))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
  gamma gamma_rn
  &lt;dbl&gt;    &lt;dbl&gt;
1  1.91    0.781</code></pre>
</div>
</div>
<p>We can now assess accuracy of the topic-document distributions. Above we used the <code>hellinger()</code> method for two matrices. The method for two dataframes requires specifying the id, topic, and probability columns. The tile plot shows that the true and fitted topics are aligned (because we used the rotation when extracting <code>gamma_df</code> above), and so again we can get an overall summary from the diagonal. Without renormalization, in the current simulation the mean Hellinger distance is 0.24 — not too bad, but perhaps larger than one would like. With larger values of <span class="math inline">\(k\)</span>, this accuracy increases significantly. Renormalization keeps the mean distance around 0.13, slightly better the the word-topic distributions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="do">## w/o renormalization, mean distance is .24</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hellinger</span>(theta_df, doc,</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">topicsdf2 =</span> gamma_df, <span class="at">id2 =</span> document, </span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">prob2 =</span> gamma, <span class="at">df =</span> <span class="cn">FALSE</span>) <span class="sc">|&gt;</span> </span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">diag</span>() <span class="sc">|&gt;</span> </span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.08499 0.20131 0.23733 0.23770 0.27244 0.37585 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="do">## w/ renormalization, mean distance drops to .13</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>doc_compare <span class="ot">=</span> <span class="fu">hellinger</span>(theta_df, doc,</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">topicsdf2 =</span> gamma_df, <span class="at">id2 =</span> document, </span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">prob2 =</span> gamma_rn, <span class="at">df =</span> <span class="cn">TRUE</span>)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>doc_compare <span class="sc">|&gt;</span> </span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(doc <span class="sc">==</span> document) <span class="sc">|&gt;</span> </span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pull</span>(dist) <span class="sc">|&gt;</span> </span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.02651 0.10375 0.12261 0.12562 0.14692 0.28277 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(doc_compare, <span class="fu">aes</span>(<span class="fu">as.integer</span>(doc), </span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">as.integer</span>(document), </span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">fill =</span> <span class="dv">1</span> <span class="sc">-</span> dist)) <span class="sc">+</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_raster</span>() <span class="sc">+</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_discrete</span>(<span class="at">breaks =</span> <span class="cn">NULL</span>, <span class="at">name =</span> <span class="st">'true'</span>) <span class="sc">+</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_discrete</span>(<span class="at">breaks =</span> <span class="cn">NULL</span>, <span class="at">name =</span> <span class="st">'fitted'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>STM has a slightly closer fit, with a mean Hellinger distance of 0.08.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>fitted_stm_gamma <span class="ot">=</span> <span class="fu">tidy</span>(fitted_stm, <span class="at">matrix =</span> <span class="st">'gamma'</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> <span class="st">'topic'</span>, </span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">values_from =</span> <span class="st">'gamma'</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">column_to_rownames</span>(<span class="st">'document'</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>()</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a><span class="fu">hellinger</span>(theta, fitted_stm_gamma <span class="sc">%*%</span> <span class="fu">t</span>(rotation_stm)) <span class="sc">|&gt;</span> </span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">diag</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.03216 0.07148 0.08638 0.08823 0.10260 0.19884 </code></pre>
</div>
</div>
</section>
</section>
<section id="example-2-victorian-fiction" class="level1">
<h1>Example 2: Victorian fiction</h1>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Strictly speaking, PCA and factor analysis are two different analytical tasks. Factor analysis models are typically fit by optimizing a maximum likelihood model, rather than an algebraic method like SVD. And the rotation introduced in the next sentence means that the new variables are not orthogonal/uncorrelated and are not ordered from greatest to least variance, which are key desiderata of PCA. Nonetheless, the approach to topic modeling proposed by <span class="citation" data-cites="RoheVintageFactorAnalysis2020">@RoheVintageFactorAnalysis2020</span> combines PCA with varimax.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Orthogonal matrices have the property that <span class="math inline">\(T^t = T^{-1}\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>For <span class="math inline">\(P\)</span>, each row corresponds to the elementwise square root of one distribution <span class="math inline">\(\sqrt p_i\)</span> and each column to one component <span class="math inline">\(x \in X\)</span>, i.e., a cell contains the value <span class="math inline">\(\sqrt{p_i(x)}\)</span>. <span class="math inline">\(Q\)</span> is the transpose, with each row corresponding to one component <span class="math inline">\(x \in X\)</span> and each column corresponding to the square root of a distribution <span class="math inline">\(\sqrt q_j\)</span>. The product of these matrices is a <span class="math inline">\(i \times j\)</span> matrix with each cell the desired sum for <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>