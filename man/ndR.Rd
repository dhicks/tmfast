% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/information_gain.R
\name{ndR}
\alias{ndR}
\title{Information gain (length-proportional distribution)}
\usage{
ndR(dataf, doc_col, term_col, count_col)
}
\arguments{
\item{dataf}{Tidy document-term matrix}

\item{doc_col}{Column of \code{dataf} with document IDs}

\item{term_col}{Column of \code{dataf} with terms}

\item{count_col}{Column of \code{dataf} with document-term counts}
}
\value{
Dataframe with columns

\if{html}{\out{<div class="sourceCode">}}\preformatted{- `\{\{ term col \}\}`, term
- `n`, total count of term occurrence
- `dR`, information gain relative to length-proportional distribution over documents
- `ndR`, \eqn{\log_2 n \times \delta R}
}\if{html}{\out{</div>}}
}
\description{
An alternative to \code{ndH()} that uses information gain relative to a distribution of documents that is proportional to length.  With the uniform distribution and dramatic differences in document lengths (eg, over a few orders of magnitude), high-ndH terms tend to be distinctive terms from very long documents.  With the length-proportional distribution, high information-gain terms are more likely to come from shorter documents. Informal testing suggests this approach performs better than the \code{ndH()} uniform distribution when documents have widely varying lengths, eg, over a few orders of magnitude.
}
\examples{
library(tidyverse)
library(tidytext)
library(janeaustenr)
austen_df = austen_books() |>
    unnest_tokens(term, text, token = 'words') |>
    mutate(author = 'Jane Austen') |>
    count(author, book, term)
ndR(austen_df, book, term, n)
}
